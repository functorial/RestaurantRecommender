{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Defining and Training Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import pickle\r\n",
    "from numpy import log, sqrt, log2, ceil, exp"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with open(\"train_sequences_padded_dataset.pkl\", \"rb\") as file:\r\n",
    "    train_sequences_padded_dataset = pickle.load(file)\r\n",
    "\r\n",
    "with open(\"vendors_tensor.pkl\", \"rb\") as file:\r\n",
    "    vendors_tensor = pickle.load(file)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define DataLoaders\r\n",
    "\r\n",
    "batch_size = 512\r\n",
    "num_workers = 0\r\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_sequences_padded_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model 1\r\n",
    "<p align=\"center\">\r\n",
    "  <img src=\"Recommender1.png\" width=\"1000\"/>\r\n",
    "</p>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define column indices to split columns into chunks (hard-coded)\r\n",
    "\r\n",
    "cont_idx_lo = 0\r\n",
    "cont_idx_hi = 8     # Up to avg_sale_log\r\n",
    "misc_idx_hi = 12    # Up to rank\r\n",
    "ptag_idx_hi = 55    # Up to primary_tags_is_42\r\n",
    "vtag_idx_hi = 123   # Up to vendor_tag_is_67"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(ceil(log2(67)))   # vtag embed size"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(ceil(log2(42)))   # ptag embed size"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(2 * ceil(log2(12+6+7)))   # final embed size"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Model1(nn.Module):\r\n",
    "    def __init__(self, vendors, cont_idx_hi, misc_idx_hi, ptag_idx_hi, vtag_idx_hi, d_fc):\r\n",
    "        super(Model1, self).__init__()\r\n",
    "\r\n",
    "        # for vendor lookup \r\n",
    "        self.vendor_lookup = nn.Embedding.from_pretrained(vendors)\r\n",
    "        self.vendor_lookup.weight.requires_grad = False\r\n",
    "\r\n",
    "        # indices for slicing inputs\r\n",
    "        self.cont_idx_hi = cont_idx_hi\r\n",
    "        self.misc_idx_hi = misc_idx_hi\r\n",
    "        self.ptag_idx_hi = ptag_idx_hi\r\n",
    "        self.vtag_idx_hi = vtag_idx_hi\r\n",
    "        \r\n",
    "        # dimensions of slices\r\n",
    "        d_cont = cont_idx_hi\r\n",
    "        d_misc = misc_idx_hi - cont_idx_hi\r\n",
    "        d_ptag = ptag_idx_hi - misc_idx_hi\r\n",
    "        d_vtag = vtag_idx_hi - ptag_idx_hi\r\n",
    "\r\n",
    "        # primary_tags embeddings\r\n",
    "        d_emb_ptag = int(ceil(log2(d_ptag)))\r\n",
    "        self.c_emb_ptag = nn.Linear(d_ptag, d_emb_ptag)\r\n",
    "        self.v_emb_ptag = nn.Linear(d_ptag, d_emb_ptag)\r\n",
    "\r\n",
    "        # vendor_tag embeddings\r\n",
    "        d_emb_vtag = int(ceil(log2(d_vtag)))\r\n",
    "        self.c_emb_vtag = nn.Linear(d_vtag, d_emb_vtag)\r\n",
    "        self.v_emb_vtag = nn.Linear(d_vtag, d_emb_vtag)\r\n",
    "\r\n",
    "        # customer and vendor embeddings\r\n",
    "        d_emb = ceil(log2(d_cont+d_misc+d_emb_ptag+d_emb_vtag))\r\n",
    "        self.c_emb = nn.Linear(d_cont+d_misc+d_emb_ptag+d_emb_vtag, d_emb)\r\n",
    "        self.v_emb = nn.Linear(d_cont+d_misc+d_emb_ptag+d_emb_vtag, d_emb)\r\n",
    "\r\n",
    "        # dense layers\r\n",
    "        self.fc1 = nn.Linear(2 * d_emb, d_fc)\r\n",
    "        self.fc2 = nn.Linear(d_fc, d_fc // 2)\r\n",
    "        self.fc3 = nn.Linear(d_fc // 2, d_fc // 4)\r\n",
    "        self.fc4 = nn.Linear(d_fc // 4, 1)\r\n",
    "\r\n",
    "\r\n",
    "    def forward(self, c_seq, v_id):\r\n",
    "        # lookup customer and vendor representations\r\n",
    "        vendor = self.vendor_lookup(v_id)\r\n",
    "        customer = torch.sum(self.vendor_lookup(c_seq), axis=1)     # correct axis?\r\n",
    "\r\n",
    "        # split customer\r\n",
    "        c_cont = customer[:, : self.cont_idx_hi]\r\n",
    "        c_misc = customer[:, self.cont_idx_hi : self.misc_idx_hi]\r\n",
    "        c_ptag = customer[:, self.misc_idx_hi : self.ptag_idx_hi]\r\n",
    "        c_vtag = customer[:, self.ptag_idx_hi :]\r\n",
    "\r\n",
    "        # split vendor\r\n",
    "        v_cont = vendor[:, : self.cont_idx_hi]\r\n",
    "        v_misc = vendor[:, self.cont_idx_hi : self.misc_idx_hi]\r\n",
    "        v_ptag = vendor[:, self.misc_idx_hi : self.ptag_idx_hi]\r\n",
    "        v_vtag = vendor[:, self.ptag_idx_hi :]\r\n",
    "\r\n",
    "        # embed ptags\r\n",
    "        c_ptag = self.c_emb_ptag(c_ptag)\r\n",
    "        c_ptag = F.elu(c_ptag)\r\n",
    "\r\n",
    "        v_ptag = self.v_emb_ptag(v_ptag)\r\n",
    "        v_ptag = F.elu(v_ptag)\r\n",
    "\r\n",
    "        # embed vtags\r\n",
    "        c_vtag = self.c_emb_vtag(c_vtag)\r\n",
    "        c_vtag = F.elu(c_vtag)\r\n",
    "\r\n",
    "        v_vtag = self.v_emb_vtag(v_vtag)\r\n",
    "        v_vtag = F.elu(v_vtag)\r\n",
    "\r\n",
    "        # embed customer\r\n",
    "        customer = torch.cat((c_cont, c_misc, c_ptag, c_vtag), axis=1)\r\n",
    "        customer = self.c_emb(customer)\r\n",
    "        customer = F.elu(customer)\r\n",
    "\r\n",
    "        # embed vendor\r\n",
    "        vendor = torch.cat((v_cont, v_misc, v_ptag, v_vtag), axis=1)\r\n",
    "        vendor = self.v_emb(vendor)\r\n",
    "        vendor = F.elu(vendor)\r\n",
    "\r\n",
    "        # feed through classifier\r\n",
    "        out = torch.cat((customer, vendor), axis=1)\r\n",
    "        out = self.fc1(out)\r\n",
    "        out = F.elu(out)\r\n",
    "\r\n",
    "        out = self.fc2(out)\r\n",
    "        out = F.elu(out)\r\n",
    "\r\n",
    "        out = self.fc3(out)\r\n",
    "        out = F.elu(out)\r\n",
    "\r\n",
    "        out = self.fc4(out)     # output is raw\r\n",
    "        return out\r\n",
    "\r\n",
    "model1 = Recommender1(vendors=vendors_tensor, cont_idx_hi=cont_idx_hi, misc_idx_hi=misc_idx_hi, ptag_idx_hi=ptag_idx_hi, vtag_idx_hi=vtag_idx_hi, d_fc=64)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loss Function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define ranking loss\r\n",
    "\r\n",
    "def sigmoid(x):\r\n",
    "    return 1/(1+exp(-x))\r\n",
    "\r\n",
    "def ranking_loss(pos_pred, neg_pred):\r\n",
    "    return 1 - sigmoid(pos_pred - neg_pred)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Optimizer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "optimizer = torch.optim.Adam(model1.parameters())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define the training process for Model 1 TODO\r\n",
    "\r\n",
    "epochs=100\r\n",
    "print_every=10\r\n",
    "\r\n",
    "for epoch in range(epochs):\r\n",
    "    running_loss = 0.0\r\n",
    "    for i, X in enumerate(train_loader):\r\n",
    "        pos_pred = model1.forward(X)\r\n",
    "        neg_sample = \r\n",
    "\r\n",
    "def train(model, dataloader, loss, optimizer, epochs:int=100, print_every:int=10):\r\n",
    "    for epoch in range(epochs):\r\n",
    "        running_loss = 0.0\r\n",
    "        for i, (X, y) in enumerate(dataloader):\r\n",
    "            \r\n",
    "            y_score = model.forward(X)\r\n",
    "            pred_loss = loss(y_score, y)\r\n",
    "            running_loss += pred_loss.item()\r\n",
    "            pred_loss.backward()\r\n",
    "            optimizer.step()\r\n",
    "            optimizer.zero_grad()\r\n",
    "        if epoch % print_every == 0:\r\n",
    "            print(f'Epoch [{epoch}/{epochs}]: sum(batch_losses) = {running_loss:.4f}')\r\n",
    "    print(f'Epoch [{epochs}/{epochs}]: sum(batch_losses) = {running_loss:.4f}')\r\n",
    "    print('Done!')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}